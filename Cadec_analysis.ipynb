{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4f9538-604a-45b3-8140-bacd01fd1e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mamtaudai/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from rapidfuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2cc324f-c255-4c02-ae73-be44fdecb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "data_root = '/Users/mamtaudai/Downloads/cadec'\n",
    "text_dir = os.path.join(data_root, 'text')\n",
    "original_dir = os.path.join(data_root, 'original')\n",
    "meddra_dir = os.path.join(data_root, 'meddra')\n",
    "sct_dir = os.path.join(data_root, 'sct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dd30e9b-31d4-4235-b3d4-b27378d8fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [f for f in os.listdir(text_dir) if f.endswith('.txt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef82e56-04d3-4c32-9790-a6dc4b2ebf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single demo file\n",
    "demo_file = 'LIPITOR.86.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c5015ee-537a-4ccd-ba4d-d495b02296ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping for d4data/biomedical-ner-all\n",
    "label_map = {\n",
    "    'SIGN_SYMPTOM': 'ADR',\n",
    "    'BIOLOGICAL_STRUCTURE': 'ADR',\n",
    "    'SEVERITY': 'ADR',\n",
    "    'DISEASE': 'Disease',\n",
    "    'CHEMICAL': 'Drug',\n",
    "    'ADR': 'ADR'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd54d79-7e65-4f29-b9e3-f01b1d28f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#  Load NER pipeline \n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=\"d4data/biomedical-ner-all\", aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67892a03-50ec-4657-af9e-4310a6cc380b",
   "metadata": {},
   "source": [
    "#  Helper functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd6a5ec-9903-4eed-b07b-2fb8bb32d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(filepath):\n",
    "    entities = set()\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            _, label_and_ranges, text = parts\n",
    "            label = label_and_ranges.split()[0]\n",
    "            entities.add((label, text.lower()))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917a417b-8f2f-4dc8-b9df-4a8fdd3c13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_adr(filepath):\n",
    "    adrs = set()\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            _, _, text = parts\n",
    "            adrs.add(('ADR', text.lower()))\n",
    "    return adrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9819a3c1-12dd-412e-86d7-cc6f5494697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_file(fname, text_dir, original_dir, ner_pipeline, label_map):\n",
    "    text_path = os.path.join(text_dir, fname)\n",
    "    with open(text_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        post_text = f.read()\n",
    "\n",
    "    ner_results = ner_pipeline(post_text)\n",
    "    \n",
    "    # Map predictions\n",
    "    pred_entities = set()\n",
    "    for entity in ner_results:\n",
    "        text = entity['word'].strip().lower()\n",
    "        model_label = entity['entity_group'].upper().replace(\"-\", \"_\")\n",
    "        if model_label in label_map:\n",
    "            cadec_label = label_map[model_label]\n",
    "            pred_entities.add((cadec_label, text))\n",
    "            \n",
    "    # Load ground truth\n",
    "    ann_fname = fname.replace('.txt', '.ann')\n",
    "    gt_entities = extract_entities(os.path.join(original_dir, ann_fname))\n",
    "\n",
    "    # Fuzzy match predictions\n",
    "    tp = 0\n",
    "    for pred_label, pred_text in pred_entities:\n",
    "        for gt_label, gt_text in gt_entities:\n",
    "            if pred_label == gt_label and fuzz.partial_ratio(pred_text, gt_text) >= 80:\n",
    "                tp += 1\n",
    "                break\n",
    "\n",
    "    fp = len(pred_entities) - tp\n",
    "    fn = len(gt_entities) - tp\n",
    "\n",
    "    p = tp / (tp+fp) if tp+fp > 0 else 0\n",
    "    r = tp / (tp+fn) if tp+fn > 0 else 0\n",
    "    f1 = 2*p*r/(p+r) if p+r > 0 else 0\n",
    "\n",
    "# We choose Precision, Recall, and F1 as our metrics because they are standard for NER evaluation.\n",
    "# Precision measures how many predicted entities are correct.\n",
    "# Recall measures how many ground truth entities were found.\n",
    "# F1 balances both, which is especially important for imbalanced data like ADR mentions.\n",
    "    \n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a757241b-6292-49e5-9cf4-b3e102d59b99",
   "metadata": {},
   "source": [
    "# --- Task 1: Enumerate distinct entities of each type ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241cd10d-95f7-4437-8ed8-4b87c1565a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enumerating unique entities: 100%|████████| 1250/1250 [00:00<00:00, 1917.01it/s]\n"
     ]
    }
   ],
   "source": [
    "global_label_entities = defaultdict(set)\n",
    "for fname in tqdm(all_files, desc=\"Enumerating unique entities\"):\n",
    "    ann_fname = fname.replace('.txt', '.ann')\n",
    "    orig_path = os.path.join(original_dir, ann_fname)\n",
    "    with open(orig_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            _, label_and_ranges, entity_text = parts\n",
    "            label = label_and_ranges.split()[0]\n",
    "            global_label_entities[label].add(entity_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d6c92e2-eb14-45b6-a39c-6fdf87fe4391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADR: 3400 distinct entities\n",
      "Drug: 323 distinct entities\n",
      "Disease: 164 distinct entities\n",
      "Finding: 298 distinct entities\n",
      "Symptom: 148 distinct entities\n"
     ]
    }
   ],
   "source": [
    "for label, entities in global_label_entities.items():\n",
    "    print(f\"{label}: {len(entities)} distinct entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ba75b-6f3f-4ce6-b28e-ced3b97ac7ba",
   "metadata": {},
   "source": [
    "# --- Tasks 2–4: Evaluate on single file ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77716cd-9eb9-4e4a-b29a-d958ff707478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single file: LIPITOR.86.txt\n",
      "Precision: 0.88, Recall: 1.00, F1: 0.93\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = evaluate_file(demo_file, text_dir, original_dir, ner_pipeline, label_map)\n",
    "print(f\"\\nSingle file: {demo_file}\")\n",
    "print(f\"Precision: {p:.2f}, Recall: {r:.2f}, F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e647e7e-25c7-4794-a16d-f1bd2596a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper ADR evaluation on single file\n",
    "\n",
    "text_path = os.path.join(text_dir, demo_file)\n",
    "with open(text_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    post_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f8cde35-3afe-42bb-a6b9-43ed844824a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_results = ner_pipeline(post_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f21bfff-6036-4e84-89c4-ca9f4cfa3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted ADRs\n",
    "\n",
    "pred_adr_entities = set()\n",
    "for entity in ner_results:\n",
    "    text = entity['word'].strip().lower()\n",
    "    model_label = entity['entity_group'].upper().replace(\"-\", \"_\")\n",
    "    if model_label in label_map:\n",
    "        cadec_label = label_map[model_label]\n",
    "        if cadec_label == 'ADR':\n",
    "            pred_adr_entities.add((cadec_label, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75943dcc-3667-4972-ab00-b9a00132551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted ADR entities:\n",
      "{('ADR', 'side of face'), ('ADR', 'tingling'), ('ADR', 'bouts of anxiety'), ('ADR', 'depression'), ('ADR', 'headache'), ('ADR', 'severe'), ('ADR', 'pain'), ('ADR', 'loss of reason to live')}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicted ADR entities:\")\n",
    "print(pred_adr_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d20e5cc-b82b-4eea-9c8c-a21597e828dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meddra_demo = demo_file.replace('.txt', '.ann')\n",
    "meddra_adr = extract_adr(os.path.join(meddra_dir, meddra_demo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f9b87b-3d1b-4cb2-ab0e-8cfc8b3c3627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy match predicted ADRs\n",
    "\n",
    "adr_tp = 0\n",
    "for pred_label, pred_text in pred_adr_entities:\n",
    "    for gt_label, gt_text in meddra_adr:\n",
    "        if pred_label == gt_label and fuzz.partial_ratio(pred_text, gt_text) >= 80:\n",
    "            adr_tp += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e856b210-22cd-40c3-a822-26a3596ec960",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_fp = len(pred_adr_entities) - adr_tp\n",
    "adr_fn = len(meddra_adr) - adr_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcaef43c-b41c-47c5-9647-7cb1bd6936c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_p = adr_tp / (adr_tp+adr_fp) if adr_tp+adr_fp > 0 else 0\n",
    "adr_r = adr_tp / (adr_tp+adr_fn) if adr_tp+adr_fn > 0 else 0\n",
    "adr_f1 = 2*adr_p*adr_r/(adr_p+adr_r) if adr_p+adr_r > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f205ae63-99ce-492b-a74a-2b1ab83abc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ADR Precision: 0.88, Recall: 1.00, F1: 0.93\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nADR Precision: {adr_p:.2f}, Recall: {adr_r:.2f}, F1: {adr_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ce454-042f-4d51-9811-d78cca95a6d9",
   "metadata": {},
   "source": [
    "# --- Task 5: Evaluate on 50 random files ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acc7fe49-586b-44e4-a0bd-32b86dd20703",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "sample_50 = random.sample(all_files, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58da2fa2-aee8-4ee7-b7c2-dbe341cb2e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 50 random files: 100%|███████████████| 50/50 [00:07<00:00,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "for fname in tqdm(sample_50, desc=\"Evaluating 50 random files\"):\n",
    "    _, _, f1 = evaluate_file(fname, text_dir, original_dir, ner_pipeline, label_map)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a7d0c4a-f6be-4cb0-8536-0f9ed62696fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean F1 over 50 random files: 0.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMean F1 over 50 random files: {sum(f1s)/len(f1s):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9710eee-2274-47d8-bd65-2ac7f03843b5",
   "metadata": {},
   "source": [
    "# Task 6: SNOMED CT Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "159de372-e668-4052-937a-30b70510a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83dddc86-c088-41c0-a613-190c50ab462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SentenceTransformer for embedding-based similarity\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45897a7d-8f3d-454d-a03e-e2902fb595e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Combine `original` and `sct` for one file ---\n",
    "def combine_original_and_sct(fname, original_dir, sct_dir):\n",
    "    ann_path = os.path.join(original_dir, fname.replace('.txt', '.ann'))\n",
    "    sct_path = os.path.join(sct_dir, fname.replace('.txt', '.ann'))\n",
    "\n",
    "    # Parse original annotations\n",
    "    id_to_label_text = {}\n",
    "    with open(ann_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) != 3:\n",
    "                continue\n",
    "            id_, label_and_range, text = parts\n",
    "            label = label_and_range.split()[0]\n",
    "            id_to_label_text[id_] = (label, text)\n",
    "\n",
    "    # Parse SCT annotations\n",
    "    combined = []\n",
    "    with open(sct_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            id_, code_and_term, _, text = parts[0], parts[1], parts[-2], parts[-1]\n",
    "            id_no_T = id_[1:]  # remove extra T\n",
    "            if id_no_T in id_to_label_text:\n",
    "                label, gt_text = id_to_label_text[id_no_T]\n",
    "                parts = code_and_term.split('|')\n",
    "                if len(parts) >= 2:\n",
    "                   code, term = parts[:2]\n",
    "                else:\n",
    "                   code = parts[0].strip()\n",
    "                   term = 'N/A'\n",
    "\n",
    "                combined.append({\n",
    "                    'SNOMED_Code': code.strip(),\n",
    "                    'SNOMED_Term': term.strip(),\n",
    "                    'Label': label,\n",
    "                    'Ground_Truth_Text': gt_text.strip()\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(combined)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ceb5901e-7e96-4a3e-9e9a-b4c6f11b2d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined Original + SCT:\n",
      "           SNOMED_Code       SNOMED_Term Label         Ground_Truth_Text\n",
      "0             25064002          Headache   ADR                 headaches\n",
      "1            162397003    Pain in throat   ADR            pain in throat\n",
      "2             62507009  Pins and needles   ADR  tingling in side of face\n",
      "3             48694002           Anxiety   ADR                   anxiety\n",
      "4             35489007        Depression   ADR                depression\n",
      "5  CONCEPT_LESS 93 115               N/A   ADR    loss of reason to live\n",
      "6            422587007            Nausea   ADR                    nausea\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Apply to demo file ---\n",
    "combined_df = combine_original_and_sct(demo_file, original_dir, sct_dir)\n",
    "print(\"\\nCombined Original + SCT:\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a67e0d1-92e6-451a-a68c-f90766dfc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: For predicted ADRs, find SNOMED code by two methods ---\n",
    "\n",
    "# Get predicted ADRs\n",
    "pred_adr_texts = [text for _, text in pred_adr_entities]\n",
    "\n",
    "sct_terms = combined_df['SNOMED_Term'].tolist()\n",
    "sct_codes = combined_df['SNOMED_Code'].tolist()\n",
    "sct_texts = combined_df['Ground_Truth_Text'].tolist()\n",
    "sct_embeddings = embed_model.encode(sct_terms, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18783eb1-6b0c-4c2e-b9a3-9d74e2f7001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted ADRs and matched SNOMED concepts:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredicted ADRs and matched SNOMED concepts:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2480ab9d-c70b-4592-bd2f-946c7769bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted ADR: side of face\n",
      "Approximate Match → SNOMED: Headache (25064002), Score: 54.54545454545454\n",
      "Embedding Match   → SNOMED: Headache (25064002), Cosine Sim: 0.35\n",
      "\n",
      "Predicted ADR: tingling\n",
      "Approximate Match → SNOMED: Pain in throat (162397003), Score: 53.333333333333336\n",
      "Embedding Match   → SNOMED: Nausea (422587007), Cosine Sim: 0.51\n",
      "\n",
      "Predicted ADR: bouts of anxiety\n",
      "Approximate Match → SNOMED: Anxiety (48694002), Score: 100.0\n",
      "Embedding Match   → SNOMED: Anxiety (48694002), Cosine Sim: 0.81\n",
      "\n",
      "Predicted ADR: depression\n",
      "Approximate Match → SNOMED: Depression (35489007), Score: 100.0\n",
      "Embedding Match   → SNOMED: Depression (35489007), Cosine Sim: 1.00\n",
      "\n",
      "Predicted ADR: headache\n",
      "Approximate Match → SNOMED: Headache (25064002), Score: 100.0\n",
      "Embedding Match   → SNOMED: Headache (25064002), Cosine Sim: 1.00\n",
      "\n",
      "Predicted ADR: severe\n",
      "Approximate Match → SNOMED: Depression (35489007), Score: 54.54545454545454\n",
      "Embedding Match   → SNOMED: Depression (35489007), Cosine Sim: 0.41\n",
      "\n",
      "Predicted ADR: pain\n",
      "Approximate Match → SNOMED: Pain in throat (162397003), Score: 100.0\n",
      "Embedding Match   → SNOMED: Headache (25064002), Cosine Sim: 0.59\n",
      "\n",
      "Predicted ADR: loss of reason to live\n",
      "Approximate Match → SNOMED: Depression (35489007), Score: 50.0\n",
      "Embedding Match   → SNOMED: Depression (35489007), Cosine Sim: 0.47\n"
     ]
    }
   ],
   "source": [
    "for pred_text in pred_adr_texts:\n",
    "    # (a) Approximate string match\n",
    "    best_match_idx = -1\n",
    "    best_score = -1\n",
    "    for i, term in enumerate(sct_terms):\n",
    "        score = fuzz.partial_ratio(pred_text, term.lower())\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match_idx = i\n",
    "    approx_code = sct_codes[best_match_idx]\n",
    "    approx_term = sct_terms[best_match_idx]\n",
    "\n",
    "    # (b) Embedding similarity\n",
    "    pred_emb = embed_model.encode(pred_text, convert_to_tensor=True)\n",
    "    cos_sim = util.cos_sim(pred_emb, sct_embeddings)[0]\n",
    "    best_idx_emb = cos_sim.argmax().item()\n",
    "    emb_code = sct_codes[best_idx_emb]\n",
    "    emb_term = sct_terms[best_idx_emb]\n",
    "\n",
    "    print(f\"\\nPredicted ADR: {pred_text}\")\n",
    "    print(f\"Approximate Match → SNOMED: {approx_term} ({approx_code}), Score: {best_score}\")\n",
    "    print(f\"Embedding Match   → SNOMED: {emb_term} ({emb_code}), Cosine Sim: {cos_sim[best_idx_emb]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d48a3e-a65e-4eaa-af51-d20562fc22c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
